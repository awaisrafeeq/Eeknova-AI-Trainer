**IDEA (new Feature)**

**1\) Wake Word (local)**

* Microphone always listening **only for â€œHey Eeknovaâ€** using **Porcupine** (offline). 

* When detected â†’ trigger UI â€œassistant modeâ€.

**2\) UI behavior on wake**

* Avatar **zooms to close-up** (camera move \+ slight head turn toward user)

* Show overlay:

  * â€œListeningâ€¦â€

  * Mic waveform

  * Language toggle (Auto / English / à°¤à±†à°²à±à°—à± / à¤¹à¤¿à¤‚à¤¦à¥€ / à®¤à®®à®¿à®´à¯ / à²•à²¨à³à²¨à²¡)

**3\) STT (Speech-to-Text)**

* Stream recorded audio to backend:

  * Use **OpenAI Speech-to-Text** endpoint OR Azure STT. 

**4\) LLM response (your existing backend)**

* Backend sends the transcript \+ instructions:

  * â€œReply in simple layman languageâ€

  * â€œUse slow polite toneâ€

  * â€œIf user requested native language, reply in that language; else Englishâ€

* Get response text.

**5\) TTS (Text-to-Speech)**

* Use **Azure TTS** (recommended) for Indian languages \+ SSML slow rate.   
  or **Google TTS** as alternative.   
  or **OpenAI TTS** for a unified stack. 

**6\) Facial \+ lip sync**

* Drive face using:

  * **visemes / blendshapes** (ARK64) mapped from phonemes (TTS providers can output viseme events or you can approximate)

* While speaking:

  * eye blinks, micro head nods, â€œlistening faceâ€ â†’ â€œspeaking faceâ€ transitions

 **Alternatives to â€œHey Eeknovaâ€ Wake Word (No Local Wake Detection)**

**ğŸ¥‡ Option 1: Touch / Gesture Activation (BEST for Holobox MVP)**

**How it works**

* User **taps the Holobox screen** OR

* User taps a floating **â€œAsk Eeknovaâ€ mic button**

* Avatar immediately:

  * zooms to close-up

  * changes expression to â€œlisteningâ€

  * starts voice interaction

**Why this is excellent**

* âœ… No always-on mic

* âœ… No false triggers

* âœ… Very intuitive for Indian users

* âœ… Perfect for public / community spaces

* âœ… Zero extra wake-word SDK cost

**UI pattern**

* Persistent mic icon (top-right or bottom-right)

* Optional gesture:

  * Raise hand

  * Touch avatar shoulder

  * Tap screen twice

**Recommendation**

ğŸ‘‰ **Use this as default MVP activation**

**My Recommendation:**

1) **Wake Word**  
   Choosing option 1 touch activation for wake up

2) **UI Behavior on wake**  
* **Zoom to close-up** can be done.  
* Show overlay can be done and language toggle using **OpenAI Realtime API.**  
3) **STT**  
   Using **Realtime API** for this.  
     
4) **LLM response**  
   This can be doable by **Realtime API**  
     
5) **TTS**  
   This is also provided by OpenAI Realtime API and this API is feasible in it.

6) **Facial \+ lip sync**  
   Lip syncing was also implemented and facials will be done by blendshapes events.  
   

**Key Implementation:**

* **Speech rate:** In Realtime API there is a feature of speech rate manipulation.  
* **Language Selection UX:** This will also be done using RealTime API  
* **Privacy:** As per client desired.  
* **Fail-safe:** As per client desired.

**NOTE:** Implementation and testing will be done in 2-3 days